{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import sys,os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy import linalg\n",
    "from numpy import dot\n",
    "import geomloss as gs\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as D\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import grad\n",
    "import torch.utils.data\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.nn.modules import Linear\n",
    "from torch.autograd.functional import jacobian,hessian,vjp,vhp,hvp\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "FilePath = 'C:\\\\Users\\\\gaojx\\\\Desktop\\\\JumpDiffusion\\\\'\n",
    "\n",
    "file_list = ['GSM1599494_ES_d0_main.csv', 'GSM1599497_ES_d2_LIFminus.csv', 'GSM1599498_ES_d4_LIFminus.csv', 'GSM1599499_ES_d7_LIFminus.csv']\n",
    "\n",
    "table_list = []\n",
    "for filein in file_list:\n",
    "    table_list.append(pd.read_csv(FilePath+filein, header=None))\n",
    "\n",
    "matrix_list = []\n",
    "gene_names = table_list[0].values[:,0]\n",
    "for table in table_list:\n",
    "    matrix_list.append(table.values[:,1:].astype('float32'))\n",
    "\n",
    "cell_counts = [matrix.shape[1] for matrix in matrix_list]\n",
    "\n",
    "# 正则化方法\n",
    "def normalize_run(mat):\n",
    "    rpm = np.sum(mat,0)/1e6\n",
    "    detect_pr = np.sum(mat==0,0)/float(mat.shape[0])\n",
    "    return np.log(mat*(np.median(detect_pr)/detect_pr)*1.0/rpm + 1.0)\n",
    "\n",
    "norm_mat = [normalize_run(matrix) for matrix in matrix_list]\n",
    "\n",
    "# 基因的重要性排序基于wasserstein距离\n",
    "qt_mat = [np.percentile(norm_in,q=np.linspace(0,100,50),axis=1) for norm_in in norm_mat] \n",
    "wdiv=np.sum((qt_mat[0]-qt_mat[3])**2,0)\n",
    "w_order = np.argsort(-wdiv)\n",
    "\n",
    "wsub = w_order[0:100]\n",
    "\n",
    "\"\"\"## 2. Impute zero(预处理阶段的一步，和2016那篇文章方法相同),代码也是直接摘抄\"\"\"\n",
    "\n",
    "def nmf(X, latent_features, max_iter=100, error_limit=1e-6, fit_error_limit=1e-6, print_iter=200):\n",
    "    \"\"\"\n",
    "    Decompose X to A*Y\n",
    "    \"\"\"\n",
    "    eps = 1e-5\n",
    "    print('Starting NMF decomposition with {} latent features and {} iterations.'.format(latent_features, max_iter))\n",
    "    #X = X.toarray()   I am passing in a scipy sparse matrix\n",
    "\n",
    "    # mask\n",
    "    mask = np.sign(X)\n",
    "\n",
    "    # initial matrices. A is random [0,1] and Y is A\\X.\n",
    "    rows, columns = X.shape\n",
    "    A = np.random.rand(rows, latent_features) # 自己设置的，觉得有多少个隐藏维度\n",
    "    A = np.maximum(A, eps)\n",
    "\n",
    "    Y = linalg.lstsq(A, X)[0]\n",
    "    Y = np.maximum(Y, eps)\n",
    "\n",
    "    masked_X = mask * X\n",
    "    X_est_prev = dot(A, Y)\n",
    "    for i in range(1, max_iter + 1):\n",
    "        # ===== updates =====\n",
    "        # Matlab: A=A.*(((W.*X)*Y')./((W.*(A*Y))*Y'));\n",
    "        top = dot(masked_X, Y.T)\n",
    "        bottom = (dot((mask * dot(A, Y)), Y.T)) + eps\n",
    "        A *= top / bottom\n",
    "\n",
    "        A = np.maximum(A, eps)\n",
    "        # print 'A',  np.round(A, 2)\n",
    "\n",
    "        # Matlab: Y=Y.*((A'*(W.*X))./(A'*(W.*(A*Y))));\n",
    "        top = dot(A.T, masked_X)\n",
    "        bottom = dot(A.T, mask * dot(A, Y)) + eps\n",
    "        Y *= top / bottom\n",
    "        Y = np.maximum(Y, eps)\n",
    "        # print 'Y', np.round(Y, 2)\n",
    "\n",
    "\n",
    "        # ==== evaluation ====\n",
    "        if i % print_iter == 0 or i == 1 or i == max_iter:\n",
    "            print('Iteration {}:'.format(i),)\n",
    "            X_est = dot(A, Y)\n",
    "            err = mask * (X_est_prev - X_est)\n",
    "            fit_residual = np.sqrt(np.sum(err ** 2))\n",
    "            X_est_prev = X_est\n",
    "\n",
    "            curRes = linalg.norm(mask * (X - X_est), ord='fro')\n",
    "            print('fit residual', np.round(fit_residual, 4),)\n",
    "            print('total residual', np.round(curRes, 4))\n",
    "            if curRes < error_limit or fit_residual < fit_error_limit:\n",
    "                break\n",
    "    return A, Y, dot(A,Y)\n",
    "\n",
    "np.random.seed(0)\n",
    "norm_imputed = [nmf(normin[wsub,:], latent_features = len(wsub)*4, max_iter=500)[2] for normin in norm_mat]\n",
    "\n",
    "norm_adj = np.mean(norm_imputed[3],1)[:,np.newaxis]\n",
    "subvec = np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "gnvec = gene_names[w_order[subvec]]\n",
    "\n",
    "cov_mat = np.cov(norm_imputed[3][subvec,:])\n",
    "whiten = np.diag(np.diag(cov_mat)**(-0.5))\n",
    "unwhiten = np.diag(np.diag(cov_mat)**(0.5))\n",
    "\n",
    "norm_imputed2 = [np.dot(whiten,(normin - norm_adj)[subvec,:]) for normin in norm_imputed]\n",
    "\n",
    "\n",
    "# 多层感知机的一般类\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_in, dim_out, dim_hidden=64, num_hidden=0, activation=nn.LeakyReLU()):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        if num_hidden == 0:\n",
    "            self.linears = nn.ModuleList([nn.Linear(dim_in, dim_out)])\n",
    "        elif num_hidden >= 1:\n",
    "            self.linears = nn.ModuleList() # 需要用net.linears获取层\n",
    "            self.linears.append(nn.Linear(dim_in, dim_hidden))\n",
    "            self.linears.extend([nn.Linear(dim_hidden, dim_hidden) for _ in range(num_hidden-1)])\n",
    "            self.linears.append(nn.Linear(dim_hidden, dim_out))\n",
    "        else:\n",
    "            raise Exception('number of hidden layers must be positive')\n",
    "\n",
    "        for m in self.linears:\n",
    "            #nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            nn.init.uniform_(m.bias,a=-0.1,b=0.1)\n",
    "            #nn.init.constant_(m.bias,0) ## bias初始化为0\n",
    " \n",
    "        self.activation = activation # 激活函数\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 最后一层到输出层不需要激活函数\n",
    "        for m in self.linears[:-1]:\n",
    "            x = self.activation(m(x))\n",
    "            #x = F.dropout(x,p=0.5)\n",
    "\n",
    "        return self.linears[-1](x)\n",
    "\n",
    "# 定义生成器网络\n",
    "class JumpEulerForwardCuda(nn.Module):\n",
    "    def __init__(self,in_features,num_hidden,dim_hidden,step_size):\n",
    "        super(JumpEulerForwardCuda,self).__init__()\n",
    "\n",
    "        self.drift = MLP(in_features,in_features,dim_hidden,num_hidden)\n",
    "        self.intensity = torch.tensor(intensity,device=\"cuda\")\n",
    "        self.mean = nn.Parameter(0.01*torch.ones(in_features))\n",
    "        self.covHalf = nn.Parameter(0.08*torch.eye(in_features))\n",
    "        self.diffusion = nn.Parameter(torch.ones(bd,10))\n",
    "        self.in_features = in_features\n",
    "        self.jump = MLP(in_features,in_features,dim_hidden,num_hidden)\n",
    "        self.step_size = step_size\n",
    "\n",
    "    def forward(self,z0,Nsim,steps):\n",
    "\n",
    "        PopulationPath = torch.empty(size = (Nsim,steps+1,self.in_features),device=\"cuda\")\n",
    "        PopulationPath[:,0,:] = z0\n",
    "        state = z0\n",
    "\n",
    "        for i in range(1,steps+1):\n",
    "            DP = D.poisson.Poisson(self.intensity*self.step_size) ## 第一次这地方忘记乘以step_size了\n",
    "            pois = DP.sample((Nsim,1)).cuda()\n",
    "            state = state + self.drift(state)*self.step_size + math.sqrt(self.step_size)*torch.normal(0,1,size=(Nsim,bd),device=\"cuda\")@self.diffusion+\\\n",
    "                (pois*self.mean + pois**(0.5)*torch.normal(0,1,size=(Nsim,self.in_features),device=\"cuda\")@self.covHalf)*self.jump(state)\n",
    "            PopulationPath[:,i,:] = state\n",
    "        return PopulationPath\n",
    "\n",
    "\n",
    "# 数据和模型参数\n",
    "train_data = norm_imputed2\n",
    "\n",
    "train0 = torch.tensor(train_data[0],dtype=torch.float32,requires_grad = True,device=\"cuda\").t()\n",
    "train2 = torch.tensor(train_data[1],dtype=torch.float32,requires_grad = True,device=\"cuda\").t()\n",
    "train4 = torch.tensor(train_data[2],dtype=torch.float32,requires_grad = True,device=\"cuda\").t()\n",
    "train7 = torch.tensor(train_data[3],dtype=torch.float32,requires_grad = True,device=\"cuda\").t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "        \n",
    "setup_seed(80)\n",
    "\n",
    "a=gs.SamplesLoss(loss='sinkhorn',p=2,blur=0.01)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('log.out','r') as f:\n",
    "    re = f.readlines()\n",
    "\n",
    "result = []\n",
    "for i in range(len(re)):\n",
    "    if re[i].startswith(\"best_score\"):\n",
    "        value = float(re[i][12:].strip())\n",
    "        if value < 3.0:\n",
    "            #print(\"第{0}行,值为{1}\".format(i,a))\n",
    "            par = re[i+1]\n",
    "            par = par[18:].strip()\n",
    "            result.append(eval(par))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "setup_seed(80)\n",
    "all = []\n",
    "for baseline in range(40):\n",
    "    HyperParameter = result[baseline]\n",
    "    intensity = HyperParameter['intensity']\n",
    "    bd = HyperParameter['bd']\n",
    "    ceng = HyperParameter['dim_hidden']\n",
    "    kuan = HyperParameter['hidden_size']\n",
    "    step_size = HyperParameter['step_size']\n",
    "    beishu = HyperParameter['beishu']\n",
    "\n",
    "    print(\"Baseline {0}\".format(baseline))\n",
    "\n",
    "    netG0 = JumpEulerForwardCuda(10,ceng,kuan,step_size).cuda()\n",
    "    netG0.load_state_dict(torch.load('./hyperparameter40/Task'+str(baseline)+'.pt'))\n",
    "\n",
    "    path0 = netG0(train0,train0.shape[0],int(3.5*beishu))\n",
    "\n",
    "    if beishu==20:\n",
    "        path0 = path0[:,[2*n for n in range(36)],:]\n",
    "        \n",
    "    error = [[] for _ in range(40)]   \n",
    "    for task in range(40):\n",
    "        HyperParameter = result[task]\n",
    "        intensity = HyperParameter['intensity']\n",
    "        bd = HyperParameter['bd']\n",
    "        ceng = HyperParameter['dim_hidden']\n",
    "        kuan = HyperParameter['hidden_size']\n",
    "        step_size = HyperParameter['step_size']\n",
    "        beishu = HyperParameter['beishu']\n",
    "\n",
    "        print(\"Task {0}\".format(task))\n",
    "\n",
    "        netG = JumpEulerForwardCuda(10,ceng,kuan,step_size).cuda()\n",
    "        netG.load_state_dict(torch.load('./hyperparameter40/Task'+str(task)+'.pt'))\n",
    "\n",
    "        path = netG(train0,train0.shape[0],int(3.5*beishu))\n",
    "\n",
    "        if beishu==20:\n",
    "            path = path[:,[2*n for n in range(36)],:]\n",
    "        \n",
    "        \n",
    "        for step in range(36):\n",
    "            discre = (a(path[:,step,:],path0[:,step,:])).item()\n",
    "            error[task].append(discre)\n",
    "            \n",
    "    all.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the baseline with minimum variance\n",
    "for i in range(40):\n",
    "    base_i = np.sum(np.array(all[i])**2)/40\n",
    "    print(base_i)\n",
    "    \n",
    "## baseline 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "baseline = 13\n",
    "HyperParameter = result[baseline]\n",
    "intensity = HyperParameter['intensity']\n",
    "bd = HyperParameter['bd']\n",
    "ceng = HyperParameter['dim_hidden']\n",
    "kuan = HyperParameter['hidden_size']\n",
    "step_size = HyperParameter['step_size']\n",
    "beishu = HyperParameter['beishu']\n",
    "\n",
    "netG0 = JumpEulerForwardCuda(10,ceng,kuan,step_size).cuda()\n",
    "netG0.load_state_dict(torch.load('./hyperparameter40/Task'+str(baseline)+'.pt'))\n",
    "\n",
    "path0 = netG0(train0,train0.shape[0],int(3.5*beishu))\n",
    "\n",
    "if beishu==20:\n",
    "    path0 = path0[:,[2*n for n in range(36)],:]\n",
    "    \n",
    "error0 = [0,(a(path[:,10,:],train2)).item(),(a(path[:,20,:],train4)).item(),(a(path[:,35,:],train7)).item()]\n",
    "print(error0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "plt.figure(figsize=(8,8),dpi=350)\n",
    "\n",
    "error = np.array(all[13])\n",
    "cov = np.sum(err**2,axis=0)/40\n",
    "\n",
    "print(cov**0.5)\n",
    "\n",
    "plt.plot(np.linspace(0,35,num=36),cov**0.5)\n",
    "plt.scatter(np.linspace(0,35,num=36),cov**0.5,label=\"Standard Deviation\")\n",
    "\n",
    "plt.scatter([0,10,20,35],error0,color=\"red\",label=\"Training Error\")\n",
    "\n",
    "plt.xlabel(\"Time (steps)\")\n",
    "plt.ylabel(\"Sinkhorn distance\")\n",
    "    \n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"sd.jpg\",format=\"jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "\n",
    "plt.figure(figsize=(16,8),dpi=350)\n",
    "\n",
    "plt.xlabel(\"Time (steps)\")\n",
    "plt.ylabel(\"Sinkhorn distance\")\n",
    "\n",
    "plt.boxplot([[x[i] for x in error] for i in range(36)],showfliers=False)\n",
    "plt.savefig(\"box.jpg\",format=\"jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## parameter set\n",
    "for i in range(40):\n",
    "    print(i+1,result[i]['intensity'],result[i]['step_size'],result[i]['dim_hidden'],result[i]['hidden_size'],result[i]['beishu'],result[i]['bd'],result[i]['learning_rate'],result[i]['n_critic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "plt.figure(figsize=(16,8),dpi=350)\n",
    "for i in range(40):\n",
    "    if i!=13:\n",
    "        plt.plot(np.linspace(0,36,num=36),error[i])\n",
    "        \n",
    "plt.xlabel(\"Time (steps)\")\n",
    "plt.ylabel(\"Sinkhorn distance\")\n",
    "\n",
    "plt.savefig(\"error.jpg\",format=\"jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time25 = [x[25] for x in error]\n",
    "time25sort = sorted(time25)\n",
    "\n",
    "for i in range(30,40):\n",
    "    ind = time25.index(time25sort[i])\n",
    "    print(ind)\n",
    "    print(\"intensity\",result[ind][\"intensity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
